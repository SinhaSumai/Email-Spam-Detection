# -*- coding: utf-8 -*-
"""EMAIL SPAM_422 Project_G5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dr5gcN_ruE2Gy9LSSCAMxrz7w84Kv3eM

DATASET https://www.kaggle.com/datasets/shantanudhakadd/email-spam-detection-dataset-classification
"""

#some imported libraries
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

"""# 1. **Read dataset**"""

import numpy as np
import pandas as pd
from google.colab import drive
drive.mount('/content/drive')
mail= pd.read_csv('/content/spam.csv', encoding='latin-1')
mail.head(1600)

"""# **2. PRE-PROCESSING**

# i) Handel missing values
"""

mail.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True,axis=1)
mail.shape

mail.isnull().sum()

"""# ii) Handel  duplicate value"""

mail.duplicated().sum()

#drop duplicates if any
mail=mail.drop_duplicates()
mail.shape
mail.duplicated().sum()

mail.shape

"""#  iii) Label Encoding"""

from sklearn.preprocessing import LabelEncoder
enc = LabelEncoder()
mail['v1'] = enc.fit_transform(mail['v1'])
print(mail[['v1']].head())
print("ham = 0 and spam = 1")

import matplotlib.pyplot as plt
plt.pie(mail['v1'].value_counts(), labels=['ham','spam'],autopct="%0.2f")
plt.show()

C,D=mail['v1'].value_counts()
import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
tag=['Ham', 'Spam']
num=[C,D]
ax.bar(tag,num)
plt.show()

mail.head()

"""# iv) Filtering Text Data"""

#def tokenize(column):
  #tokens = nltk.word_tokenize(column)
  #return [w for w in tokens if w.isalpha()]

import nltk
#nltk.download('punkt');
from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()


#string
mail['v2'].dropna(inplace=True)
mail['v2'] = mail['v2'].astype(str)

#case handel
mail['v2'] = mail['v2'].str.lower()

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

stop_words = stopwords.words('english')
mail['v2'] = mail['v2'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))

# special char
mail = mail.replace(r'[^\w\s]|_', '', regex=True)

#tokenized
#mail['v2'] = mail.apply(lambda x: tokenize(x['v2']), axis=1)

#stemming
#mail['stemmed'] = mail['tokenized'].apply(lambda x: [stemmer.stem(y) for y in x])
#mail= mail.drop(columns=['tokenized'])
#mail.head()

"""# v) Feature Extraction"""

from sklearn.feature_extraction.text import CountVectorizer
count= CountVectorizer()

x=count.fit_transform(mail['v2']).toarray()
y=mail['v1']
x.shape

"""# vi) Split the dataset"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=0)

A=x_train.shape[0]
B=x_test.shape[0]

x_train.shape,x_test.shape

import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
tag=['Train', 'Test']
num=[A,B]
ax.bar(tag,num)
plt.show()

import seaborn as sn
#sns.displot(mail['v2'])

"""# **3. MODEL TRAINING (CLASSIFIER)**

**Training Mode---1)  SVC**
"""

from sklearn.svm import SVC
svc = SVC(kernel="linear")
svc.fit(x_train, y_train)

"""**Training Mode---2) Naive Bayes**"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(x_train, y_train)

"""**Training Mode---3) Logistic Regression**"""



"""# **4. ACCURACY** [for every classifier]

---

**SVC ACCURACY**
"""

print("Training accuracy of the model: ",(svc.score(x_train, y_train)))
print("Testing accuracy of the model: ",(svc.score(x_test, y_test)))

predictions = svc.predict(x_test)
print(predictions)
from sklearn.metrics import confusion_matrix
mat=confusion_matrix(predictions, y_test)
print(mat)
from seaborn import heatmap
heatmap(mat , cmap="Pastel1_r", xticklabels=['class_0' ,'class_1'], yticklabels=['class_0' ,'class_1'], annot=True)

"""**NAIVE BAYES ACCURACY**"""

print("Training accuracy of the model is {:.2f}".format(gnb.score(x_train, y_train)))
print("Testing accuracy of the model is {:.2f}".format(gnb.score(x_test, y_test)))

predictions = gnb.predict(x_test)
print(predictions)

from sklearn.metrics import confusion_matrix
mat=confusion_matrix(predictions, y_test)
print(mat)

from seaborn import heatmap
heatmap(mat , cmap="Pastel1_r", xticklabels=['class_0' ,'class_1' ,'class_2'],
        yticklabels=['class_0' ,'class_1', 'class_2'], annot=True)

"""**LOGISTIC REGRESSION ACCURACY**"""



"""# **REFERENCES**

1. Hassan, Muhammad Ali & Mtetwa, Nhamoinesu. (2018). Feature Extraction and Classification of Spam Emails. 93-98. 10.1109/ISCMI.2018.8703222.
https://www.researchgate.net/publication/332823881_Feature_Extraction_and_Classification_of_Spam_Emails
2. for logistic
https://eudl.eu/pdf/10.4108/eai.27-2-2020.2303291







"""